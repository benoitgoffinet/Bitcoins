{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea4e09b-7cd2-40de-9f3e-77766c328ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13df5bef-eb3d-4cb5-a0ac-5deb06ebce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c986d3e-61ad-4f3e-ac7e-37035f3e90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ereturn_1d\"] = df[\"return_1d\"].apply(lambda x: 0 if x < 0 else 1)\n",
    "df[\"Ereturn_3d\"] = df[\"return_3d\"].apply(lambda x: 0 if x < 0 else 1)\n",
    "df[\"Ereturn_7d\"] = df[\"return_7d\"].apply(lambda x: 0 if x < 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3134340-471c-416d-9bb1-9fcdbac896dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    337.000000\n",
       "mean       0.507418\n",
       "std        0.500688\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Ereturn_1d, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choix de la cible  \n",
    "target = df[\"Ereturn_1d\"]\n",
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522468fd-5b5d-44ac-b264-0928bd508d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataexplicative = df[['MA30', 'MA_diff', 'vol_7d', 'MA7',\n",
    "                        'vol_MA7', 'highest_30', 'lowest_30', \n",
    "                         'pos_channel_30']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf05b67-ade6-4c16-b36e-647e2e7ac248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Nombre de valeurs identiques dans Train/Test : 0\n",
      "ðŸ“Š Accuracy globale : 0.5294117647058824\n",
      "\n",
      "ðŸ”µ Classe BAISSE (0) :\n",
      "Precision : 0.5641025641025641\n",
      "Recall    : 0.5945945945945946\n",
      "F1-score  : 0.5789473684210527\n",
      "\n",
      "ðŸŸ¢ Classe HAUSSE (1) :\n",
      "Precision : 0.4827586206896552\n",
      "Recall    : 0.45161290322580644\n",
      "F1-score  : 0.4666666666666667\n",
      "\n",
      "ðŸ“„ Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      baisse       0.56      0.59      0.58        37\n",
      "      hausse       0.48      0.45      0.47        31\n",
      "\n",
      "    accuracy                           0.53        68\n",
      "   macro avg       0.52      0.52      0.52        68\n",
      "weighted avg       0.53      0.53      0.53        68\n",
      "\n",
      "ðŸ”¢ Matrice de confusion :\n",
      "[[22 15]\n",
      " [17 14]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "#X = X.drop(columns=['NiveauSiteEUIWN'])\n",
    "y = target\n",
    "\n",
    "# Encodage One-Hot basÃ© sur X\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Normalisation des donnÃ©es \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # OK : on apprend la normalisation sur l'entraÃ®nement\n",
    "X_test_scaled = scaler.transform(X_test)        # OK : on applique la mÃªme normalisation au test\n",
    "\n",
    "# Appliquer le modÃ¨le DummyRegressor\n",
    "dummy_regressor = DummyClassifier(strategy=\"stratified\")  # 'mean' pour prÃ©dire la moyenne des cibles\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prÃ©dictions\n",
    "y_pred = dummy_regressor.predict(X_test)\n",
    "\n",
    "# Calculer les erreurs\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# VÃ©rifier si des valeurs de test sont dÃ©jÃ  vues en entraÃ®nement\n",
    "intersection = set(X_train.index).intersection(set(X_test.index))\n",
    "print(f\"ðŸ” Nombre de valeurs identiques dans Train/Test : {len(intersection)}\")\n",
    "\n",
    "# Accuracy globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision par classe\n",
    "precision_baisse = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_hausse = precision_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Recall par classe\n",
    "recall_baisse = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_hausse = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# F1-score par classe\n",
    "f1_baisse = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_hausse = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"ðŸ“Š Accuracy globale :\", accuracy)\n",
    "print(\"\\nðŸ”µ Classe BAISSE (0) :\")\n",
    "print(\"Precision :\", precision_baisse)\n",
    "print(\"Recall    :\", recall_baisse)\n",
    "print(\"F1-score  :\", f1_baisse)\n",
    "\n",
    "print(\"\\nðŸŸ¢ Classe HAUSSE (1) :\")\n",
    "print(\"Precision :\", precision_hausse)\n",
    "print(\"Recall    :\", recall_hausse)\n",
    "print(\"F1-score  :\", f1_hausse)\n",
    "\n",
    "# Affichage dÃ©taillÃ© :\n",
    "print(\"\\nðŸ“„ Classification report :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"baisse\",\"hausse\"]))\n",
    "\n",
    "# Matrice de confusion :\n",
    "print(\"ðŸ”¢ Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0e7a14-a5dc-408a-bf0a-1aae8114ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š RÂ² Score: -0.4228\n",
      "ðŸ“‰ Mean Squared Error: 0.3529\n",
      "ðŸ“Š Accuracy globale : 0.6470588235294118\n",
      "\n",
      "ðŸ”µ Classe BAISSE (0) :\n",
      "Precision : 0.6666666666666666\n",
      "Recall    : 0.7027027027027027\n",
      "F1-score  : 0.6842105263157895\n",
      "\n",
      "ðŸŸ¢ Classe HAUSSE (1) :\n",
      "Precision : 0.6206896551724138\n",
      "Recall    : 0.5806451612903226\n",
      "F1-score  : 0.6\n",
      "\n",
      "ðŸ“„ Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      baisse       0.67      0.70      0.68        37\n",
      "      hausse       0.62      0.58      0.60        31\n",
      "\n",
      "    accuracy                           0.65        68\n",
      "   macro avg       0.64      0.64      0.64        68\n",
      "weighted avg       0.65      0.65      0.65        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CePC\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "#X = X.drop(columns=['NiveauSiteEUIWN'])\n",
    "y = target\n",
    "\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)  # Conversion des variables catÃ©gorielles en variables binaires\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# ðŸ”¹ Normalisation des variables explicatives uniquement\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Appliquer le scaler uniquement aux variables explicatives\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Appliquer la mÃªme transformation sur les donnÃ©es de test\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    penalty=\"elasticnet\",\n",
    "    l1_ratio=0.5,  # mÃ©lange L1/L2\n",
    "    solver=\"saga\"\n",
    ")\n",
    "# ðŸ”¹ CrÃ©ation du modÃ¨le ElasticNet avec alpha fixÃ© Ã  1\n",
    "elasticnet = logreg\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le\n",
    "elasticnet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ðŸ”¹ Faire des prÃ©dictions sur l'ensemble de test\n",
    "y_pred = elasticnet.predict(X_test_scaled)\n",
    "\n",
    "# ðŸ”¹ Ã‰valuer le modÃ¨le sur l'ensemble de test\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Affichage des rÃ©sultats\n",
    "print(f\"ðŸ“Š RÂ² Score: {r2:.4f}\")\n",
    "print(f\"ðŸ“‰ Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Faire des prÃ©dictions sur l'ensemble d'entraÃ®nement\n",
    "y_pred_train = elasticnet.predict(X_train_scaled)\n",
    "# Accuracy globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision par classe\n",
    "precision_baisse = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_hausse = precision_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Recall par classe\n",
    "recall_baisse = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_hausse = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# F1-score par classe\n",
    "f1_baisse = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_hausse = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"ðŸ“Š Accuracy globale :\", accuracy)\n",
    "print(\"\\nðŸ”µ Classe BAISSE (0) :\")\n",
    "print(\"Precision :\", precision_baisse)\n",
    "print(\"Recall    :\", recall_baisse)\n",
    "print(\"F1-score  :\", f1_baisse)\n",
    "\n",
    "print(\"\\nðŸŸ¢ Classe HAUSSE (1) :\")\n",
    "print(\"Precision :\", precision_hausse)\n",
    "print(\"Recall    :\", recall_hausse)\n",
    "print(\"F1-score  :\", f1_hausse)\n",
    "\n",
    "# Affichage dÃ©taillÃ© :\n",
    "print(\"\\nðŸ“„ Classification report :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"baisse\",\"hausse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d61e3599-1b72-4657-842a-308e4a25252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__C': 1, 'model__l1_ratio': 0.9}\n",
      "ðŸ“Š Meilleur F1_macro (validation croisÃ©e) : 0.6669\n",
      "ðŸ“Š Ã‰valuation sur TEST\n",
      "ðŸŽ¯ Accuracy        : 0.6324\n",
      "ðŸ’  F1 Macro        : 0.6284\n",
      "ðŸ”· F1 Weighted     : 0.6318\n",
      "\n",
      "ðŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.66      0.68      0.67        37\n",
      "      HAUSSE       0.60      0.58      0.59        31\n",
      "\n",
      "    accuracy                           0.63        68\n",
      "   macro avg       0.63      0.63      0.63        68\n",
      "weighted avg       0.63      0.63      0.63        68\n",
      "\n",
      "\n",
      "ðŸ§© Matrice de confusion :\n",
      "[[25 12]\n",
      " [13 18]]\n",
      "\n",
      "ðŸ“Š Ã‰valuation sur TRAIN\n",
      "ðŸŽ¯ Accuracy (train) : 0.6766\n",
      "ðŸ’  F1 Macro (train) : 0.6757\n",
      "\n",
      "ðŸ“ˆ Coefficients du modÃ¨le :\n",
      "               Feature  Coefficient\n",
      "7  num__pos_channel_30     1.562464\n",
      "5      num__highest_30     0.980137\n",
      "6       num__lowest_30     0.409556\n",
      "0            num__MA30     0.000000\n",
      "2          num__vol_7d    -0.032811\n",
      "4         num__vol_MA7    -0.252404\n",
      "1         num__MA_diff    -0.661831\n",
      "3             num__MA7    -1.117556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# ðŸŽ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,  random_state=42#, stratify = y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ðŸ”§ Pipeline de prÃ©traitement\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ðŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', LogisticRegression(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.01, 0.1, 1, 10],\n",
    "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ðŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ðŸ“Š Meilleur F1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ðŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# ðŸ“Š Ã‰valuation globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ðŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ðŸŽ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ðŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ðŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nðŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ðŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nðŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ðŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nðŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ðŸŽ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n",
    "\n",
    "# ðŸ“ˆ Extraire les coefficients du modÃ¨le\n",
    "coefs = best_model.named_steps['model'].coef_.flatten()\n",
    "features = best_model.named_steps['preprocessing'].get_feature_names_out()\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': coefs\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Coefficients du modÃ¨le :\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5644142-0656-46d8-91ae-32916f8d7c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__max_depth': 20, 'model__min_samples_split': 5, 'model__n_estimators': 50}\n",
      "ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.6664\n",
      "ðŸ“Š Ã‰valuation sur TEST\n",
      "ðŸŽ¯ Accuracy        : 0.5294\n",
      "ðŸ’  F1 Macro        : 0.5278\n",
      "ðŸ”· F1 Weighted     : 0.5253\n",
      "\n",
      "ðŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.59      0.43      0.50        37\n",
      "      HAUSSE       0.49      0.65      0.56        31\n",
      "\n",
      "    accuracy                           0.53        68\n",
      "   macro avg       0.54      0.54      0.53        68\n",
      "weighted avg       0.54      0.53      0.53        68\n",
      "\n",
      "\n",
      "ðŸ§© Matrice de confusion :\n",
      "[[16 21]\n",
      " [11 20]]\n",
      "\n",
      "ðŸ“Š Ã‰valuation sur TRAIN\n",
      "ðŸŽ¯ Accuracy (train) : 0.9851\n",
      "ðŸ’  F1 Macro (train) : 0.9851\n",
      "\n",
      "ðŸ“Š Ã‰valuation sur TEST\n",
      "ðŸŽ¯ Accuracy (test) : 0.5294\n",
      "ðŸ’  F1 Macro (test) : 0.5278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# ðŸŽ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ðŸ”§ Pipeline de prÃ©traitement\n",
    "# Nous remplaÃ§ons le OneHotEncoder par un TargetEncoder pour les variables catÃ©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ðŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state=42))  # ModÃ¨le ElasticNet\n",
    "])\n",
    "\n",
    "# ParamÃ¨tres pour GridSearchCV\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 20, 30],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__n_estimators': [10, 50, 100, 200],  # Add more parameters for the model if needed\n",
    "    'model__min_samples_split': [3, 2, 4, 5, 6]\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ðŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ðŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ðŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ðŸŽ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ðŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ðŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nðŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ðŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nðŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ðŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nðŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ðŸŽ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n",
    "\n",
    "# ðŸ”µ PrÃ©dictions TEST\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# ðŸ“Š Ã‰valuation TEST\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "print(\"\\nðŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ðŸŽ¯ Accuracy (test) : {accuracy_test:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro (test) : {f1_macro_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "336ca620-a58e-49a4-b443-bfcaa199c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__max_depth': 20, 'model__min_samples_leaf': 5, 'model__min_samples_split': 3}\n",
      "ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.6610\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__max_depth': 20, 'model__min_samples_leaf': 5, 'model__min_samples_split': 3}\n",
      "ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.6610\n",
      "ðŸ“Š Ã‰valuation sur TEST\n",
      "ðŸŽ¯ Accuracy        : 0.6324\n",
      "ðŸ’  F1 Macro        : 0.6323\n",
      "ðŸ”· F1 Weighted     : 0.6328\n",
      "\n",
      "ðŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.69      0.59      0.64        37\n",
      "      HAUSSE       0.58      0.68      0.63        31\n",
      "\n",
      "    accuracy                           0.63        68\n",
      "   macro avg       0.64      0.64      0.63        68\n",
      "weighted avg       0.64      0.63      0.63        68\n",
      "\n",
      "\n",
      "ðŸ§© Matrice de confusion :\n",
      "[[22 15]\n",
      " [10 21]]\n",
      "\n",
      "ðŸ“Š Ã‰valuation sur TRAIN\n",
      "ðŸŽ¯ Accuracy (train) : 0.8662\n",
      "ðŸ’  F1 Macro (train) : 0.8661\n"
     ]
    }
   ],
   "source": [
    "#decisiontree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "# ðŸŽ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ðŸ”§ Pipeline de prÃ©traitement\n",
    "# Nous remplaÃ§ons le OneHotEncoder par un TargetEncoder pour les variables catÃ©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ðŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))  # ModÃ¨le ElasticNet\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 20, 30],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__min_samples_leaf': [2, 3, 4, 5, 6],  # Add more parameters for the model if needed\n",
    "    'model__min_samples_split': [3, 2, 4]\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ðŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ðŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ðŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ðŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ðŸŽ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ðŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ðŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nðŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ðŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nðŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ðŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nðŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ðŸŽ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd04a4aa-6581-407d-8216-8fdf358bc5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__learning_rate': 0.3, 'model__max_depth': 5, 'model__n_estimators': 50}\n",
      "ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.7005\n",
      "ðŸ“Š Ã‰valuation sur TEST\n",
      "ðŸŽ¯ Accuracy        : 0.5588\n",
      "ðŸ’  F1 Macro        : 0.5584\n",
      "ðŸ”· F1 Weighted     : 0.5573\n",
      "\n",
      "ðŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.62      0.49      0.55        37\n",
      "      HAUSSE       0.51      0.65      0.57        31\n",
      "\n",
      "    accuracy                           0.56        68\n",
      "   macro avg       0.57      0.57      0.56        68\n",
      "weighted avg       0.57      0.56      0.56        68\n",
      "\n",
      "\n",
      "ðŸ§© Matrice de confusion :\n",
      "[[18 19]\n",
      " [11 20]]\n",
      "\n",
      "ðŸ“Š Ã‰valuation sur TRAIN\n",
      "ðŸŽ¯ Accuracy (train) : 1.0000\n",
      "ðŸ’  F1 Macro (train) : 1.0000\n"
     ]
    }
   ],
   "source": [
    "#gradientboosting\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# ðŸŽ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ðŸ”§ Pipeline de prÃ©traitement\n",
    "# Nous remplaÃ§ons le OneHotEncoder par un TargetEncoder pour les variables catÃ©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ðŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', GradientBoostingClassifier(random_state=42))  # ModÃ¨le ElasticNet\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 20, 30],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__n_estimators': [100, 200, 300, 50],  # Add more parameters for the model if needed\n",
    "    'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ðŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ðŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ðŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ðŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ðŸŽ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ðŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ðŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nðŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ðŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nðŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ðŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nðŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ðŸŽ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ðŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda Base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
