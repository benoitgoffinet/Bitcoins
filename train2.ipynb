{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea4e09b-7cd2-40de-9f3e-77766c328ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13df5bef-eb3d-4cb5-a0ac-5deb06ebce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a154a6bf-bc56-44c5-b5f0-00c425f1c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target_up\"] = (df[\"price\"].shift(-7) > df[\"price\"]).astype(int)\n",
    "df = df.iloc[:-7]   # retirer la derniÃ¨re ligne sans cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d611b254-cc86-45e7-8b21-63169a0bd467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_up\n",
       "0    0.533333\n",
       "1    0.466667\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target_up\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3134340-471c-416d-9bb1-9fcdbac896dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choix de la cible  \n",
    "\n",
    "target = df['target_up']\n",
    "target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522468fd-5b5d-44ac-b264-0928bd508d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataexplicative = df.drop(columns=['date', 'target_up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad00375-b0b6-406e-8792-f968b4e8fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58b4c7d6-8fe7-4fc4-9105-ac59b654db94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataexplicative.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8665eb-162d-4b9d-b5ca-fb622ab3773d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_7d</th>\n",
       "      <th>return_14d</th>\n",
       "      <th>MA7</th>\n",
       "      <th>MA30</th>\n",
       "      <th>MA_diff</th>\n",
       "      <th>vol_7d</th>\n",
       "      <th>vol_MA7</th>\n",
       "      <th>highest_30</th>\n",
       "      <th>lowest_30</th>\n",
       "      <th>pos_channel_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>90715.753618</td>\n",
       "      <td>5.194012e+10</td>\n",
       "      <td>2.603299</td>\n",
       "      <td>3.394501</td>\n",
       "      <td>-5.491798</td>\n",
       "      <td>-7.830561</td>\n",
       "      <td>89652.380016</td>\n",
       "      <td>93925.278544</td>\n",
       "      <td>-4272.898529</td>\n",
       "      <td>2.948904</td>\n",
       "      <td>6.566432e+10</td>\n",
       "      <td>99618.766232</td>\n",
       "      <td>87737.503329</td>\n",
       "      <td>0.250668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>91627.763812</td>\n",
       "      <td>5.843824e+10</td>\n",
       "      <td>1.005349</td>\n",
       "      <td>2.526320</td>\n",
       "      <td>-0.915840</td>\n",
       "      <td>-6.495101</td>\n",
       "      <td>89531.391469</td>\n",
       "      <td>93799.859796</td>\n",
       "      <td>-4268.468327</td>\n",
       "      <td>2.702931</td>\n",
       "      <td>6.470270e+10</td>\n",
       "      <td>99618.766232</td>\n",
       "      <td>87737.503329</td>\n",
       "      <td>0.327428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>88864.312891</td>\n",
       "      <td>6.128648e+10</td>\n",
       "      <td>-3.015954</td>\n",
       "      <td>0.509242</td>\n",
       "      <td>0.423149</td>\n",
       "      <td>-8.322142</td>\n",
       "      <td>89584.883409</td>\n",
       "      <td>93452.284640</td>\n",
       "      <td>-3867.401232</td>\n",
       "      <td>2.393804</td>\n",
       "      <td>5.990474e+10</td>\n",
       "      <td>99618.766232</td>\n",
       "      <td>87737.503329</td>\n",
       "      <td>0.094839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>87583.285613</td>\n",
       "      <td>5.463719e+10</td>\n",
       "      <td>-1.441554</td>\n",
       "      <td>-3.453058</td>\n",
       "      <td>-3.078082</td>\n",
       "      <td>-7.665657</td>\n",
       "      <td>89187.525993</td>\n",
       "      <td>93051.101953</td>\n",
       "      <td>-3863.575960</td>\n",
       "      <td>2.264400</td>\n",
       "      <td>5.813058e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>87583.285613</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>85762.206093</td>\n",
       "      <td>8.639245e+10</td>\n",
       "      <td>-2.079255</td>\n",
       "      <td>-6.401507</td>\n",
       "      <td>-2.251372</td>\n",
       "      <td>-8.316363</td>\n",
       "      <td>88905.340674</td>\n",
       "      <td>92658.963301</td>\n",
       "      <td>-3753.622627</td>\n",
       "      <td>2.130685</td>\n",
       "      <td>6.254074e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>85762.206093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price        volume  return_1d  return_3d  return_7d  return_14d  \\\n",
       "325  90715.753618  5.194012e+10   2.603299   3.394501  -5.491798   -7.830561   \n",
       "326  91627.763812  5.843824e+10   1.005349   2.526320  -0.915840   -6.495101   \n",
       "327  88864.312891  6.128648e+10  -3.015954   0.509242   0.423149   -8.322142   \n",
       "328  87583.285613  5.463719e+10  -1.441554  -3.453058  -3.078082   -7.665657   \n",
       "329  85762.206093  8.639245e+10  -2.079255  -6.401507  -2.251372   -8.316363   \n",
       "\n",
       "              MA7          MA30      MA_diff    vol_7d       vol_MA7  \\\n",
       "325  89652.380016  93925.278544 -4272.898529  2.948904  6.566432e+10   \n",
       "326  89531.391469  93799.859796 -4268.468327  2.702931  6.470270e+10   \n",
       "327  89584.883409  93452.284640 -3867.401232  2.393804  5.990474e+10   \n",
       "328  89187.525993  93051.101953 -3863.575960  2.264400  5.813058e+10   \n",
       "329  88905.340674  92658.963301 -3753.622627  2.130685  6.254074e+10   \n",
       "\n",
       "       highest_30     lowest_30  pos_channel_30  \n",
       "325  99618.766232  87737.503329        0.250668  \n",
       "326  99618.766232  87737.503329        0.327428  \n",
       "327  99618.766232  87737.503329        0.094839  \n",
       "328  98422.812122  87583.285613        0.000000  \n",
       "329  98422.812122  85762.206093        0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataexplicative.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11684d27-4a09-44ae-9592-11d567d1744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_7d</th>\n",
       "      <th>return_14d</th>\n",
       "      <th>MA7</th>\n",
       "      <th>MA30</th>\n",
       "      <th>MA_diff</th>\n",
       "      <th>vol_7d</th>\n",
       "      <th>vol_MA7</th>\n",
       "      <th>highest_30</th>\n",
       "      <th>lowest_30</th>\n",
       "      <th>pos_channel_30</th>\n",
       "      <th>target_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>90715.753618</td>\n",
       "      <td>5.194012e+10</td>\n",
       "      <td>2.603299</td>\n",
       "      <td>3.394501</td>\n",
       "      <td>-5.491798</td>\n",
       "      <td>-7.830561</td>\n",
       "      <td>89652.380016</td>\n",
       "      <td>93925.278544</td>\n",
       "      <td>-4272.898529</td>\n",
       "      <td>2.948904</td>\n",
       "      <td>6.566432e+10</td>\n",
       "      <td>99618.766232</td>\n",
       "      <td>87737.503329</td>\n",
       "      <td>0.250668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>91627.763812</td>\n",
       "      <td>5.843824e+10</td>\n",
       "      <td>1.005349</td>\n",
       "      <td>2.526320</td>\n",
       "      <td>-0.915840</td>\n",
       "      <td>-6.495101</td>\n",
       "      <td>89531.391469</td>\n",
       "      <td>93799.859796</td>\n",
       "      <td>-4268.468327</td>\n",
       "      <td>2.702931</td>\n",
       "      <td>6.470270e+10</td>\n",
       "      <td>99618.766232</td>\n",
       "      <td>87737.503329</td>\n",
       "      <td>0.327428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2025-11-12</td>\n",
       "      <td>88864.312891</td>\n",
       "      <td>6.128648e+10</td>\n",
       "      <td>-3.015954</td>\n",
       "      <td>0.509242</td>\n",
       "      <td>0.423149</td>\n",
       "      <td>-8.322142</td>\n",
       "      <td>89584.883409</td>\n",
       "      <td>93452.284640</td>\n",
       "      <td>-3867.401232</td>\n",
       "      <td>2.393804</td>\n",
       "      <td>5.990474e+10</td>\n",
       "      <td>99618.766232</td>\n",
       "      <td>87737.503329</td>\n",
       "      <td>0.094839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2025-11-13</td>\n",
       "      <td>87583.285613</td>\n",
       "      <td>5.463719e+10</td>\n",
       "      <td>-1.441554</td>\n",
       "      <td>-3.453058</td>\n",
       "      <td>-3.078082</td>\n",
       "      <td>-7.665657</td>\n",
       "      <td>89187.525993</td>\n",
       "      <td>93051.101953</td>\n",
       "      <td>-3863.575960</td>\n",
       "      <td>2.264400</td>\n",
       "      <td>5.813058e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>87583.285613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>85762.206093</td>\n",
       "      <td>8.639245e+10</td>\n",
       "      <td>-2.079255</td>\n",
       "      <td>-6.401507</td>\n",
       "      <td>-2.251372</td>\n",
       "      <td>-8.316363</td>\n",
       "      <td>88905.340674</td>\n",
       "      <td>92658.963301</td>\n",
       "      <td>-3753.622627</td>\n",
       "      <td>2.130685</td>\n",
       "      <td>6.254074e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>85762.206093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date         price        volume  return_1d  return_3d  return_7d  \\\n",
       "325  2025-11-10  90715.753618  5.194012e+10   2.603299   3.394501  -5.491798   \n",
       "326  2025-11-11  91627.763812  5.843824e+10   1.005349   2.526320  -0.915840   \n",
       "327  2025-11-12  88864.312891  6.128648e+10  -3.015954   0.509242   0.423149   \n",
       "328  2025-11-13  87583.285613  5.463719e+10  -1.441554  -3.453058  -3.078082   \n",
       "329  2025-11-14  85762.206093  8.639245e+10  -2.079255  -6.401507  -2.251372   \n",
       "\n",
       "     return_14d           MA7          MA30      MA_diff    vol_7d  \\\n",
       "325   -7.830561  89652.380016  93925.278544 -4272.898529  2.948904   \n",
       "326   -6.495101  89531.391469  93799.859796 -4268.468327  2.702931   \n",
       "327   -8.322142  89584.883409  93452.284640 -3867.401232  2.393804   \n",
       "328   -7.665657  89187.525993  93051.101953 -3863.575960  2.264400   \n",
       "329   -8.316363  88905.340674  92658.963301 -3753.622627  2.130685   \n",
       "\n",
       "          vol_MA7    highest_30     lowest_30  pos_channel_30  target_up  \n",
       "325  6.566432e+10  99618.766232  87737.503329        0.250668          0  \n",
       "326  6.470270e+10  99618.766232  87737.503329        0.327428          0  \n",
       "327  5.990474e+10  99618.766232  87737.503329        0.094839          0  \n",
       "328  5.813058e+10  98422.812122  87583.285613        0.000000          0  \n",
       "329  6.254074e+10  98422.812122  85762.206093        0.000000          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac93971-81e2-4021-8af7-67bd1a7c8cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325    0\n",
       "326    0\n",
       "327    0\n",
       "328    0\n",
       "329    0\n",
       "Name: target_up, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf05b67-ade6-4c16-b36e-647e2e7ac248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Nombre de valeurs identiques dans Train/Test : 0\n",
      "ğŸ“Š Accuracy globale : 0.48484848484848486\n",
      "\n",
      "ğŸ”µ Classe BAISSE (0) :\n",
      "Precision : 0.6551724137931034\n",
      "Recall    : 0.4418604651162791\n",
      "F1-score  : 0.5277777777777778\n",
      "\n",
      "ğŸŸ¢ Classe HAUSSE (1) :\n",
      "Precision : 0.35135135135135137\n",
      "Recall    : 0.5652173913043478\n",
      "F1-score  : 0.43333333333333335\n",
      "\n",
      "ğŸ“„ Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      baisse       0.66      0.44      0.53        43\n",
      "      hausse       0.35      0.57      0.43        23\n",
      "\n",
      "    accuracy                           0.48        66\n",
      "   macro avg       0.50      0.50      0.48        66\n",
      "weighted avg       0.55      0.48      0.49        66\n",
      "\n",
      "ğŸ”¢ Matrice de confusion :\n",
      "[[19 24]\n",
      " [10 13]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "#X = X.drop(columns=['NiveauSiteEUIWN'])\n",
    "y = target\n",
    "\n",
    "# Encodage One-Hot basÃ© sur X\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Normalisation des donnÃ©es \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # OK : on apprend la normalisation sur l'entraÃ®nement\n",
    "X_test_scaled = scaler.transform(X_test)        # OK : on applique la mÃªme normalisation au test\n",
    "\n",
    "# Appliquer le modÃ¨le DummyRegressor\n",
    "dummy_regressor = DummyClassifier(strategy=\"stratified\")  # 'mean' pour prÃ©dire la moyenne des cibles\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prÃ©dictions\n",
    "y_pred = dummy_regressor.predict(X_test)\n",
    "\n",
    "# Calculer les erreurs\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# VÃ©rifier si des valeurs de test sont dÃ©jÃ  vues en entraÃ®nement\n",
    "intersection = set(X_train.index).intersection(set(X_test.index))\n",
    "print(f\"ğŸ” Nombre de valeurs identiques dans Train/Test : {len(intersection)}\")\n",
    "\n",
    "# Accuracy globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision par classe\n",
    "precision_baisse = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_hausse = precision_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Recall par classe\n",
    "recall_baisse = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_hausse = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# F1-score par classe\n",
    "f1_baisse = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_hausse = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"ğŸ“Š Accuracy globale :\", accuracy)\n",
    "print(\"\\nğŸ”µ Classe BAISSE (0) :\")\n",
    "print(\"Precision :\", precision_baisse)\n",
    "print(\"Recall    :\", recall_baisse)\n",
    "print(\"F1-score  :\", f1_baisse)\n",
    "\n",
    "print(\"\\nğŸŸ¢ Classe HAUSSE (1) :\")\n",
    "print(\"Precision :\", precision_hausse)\n",
    "print(\"Recall    :\", recall_hausse)\n",
    "print(\"F1-score  :\", f1_hausse)\n",
    "\n",
    "# Affichage dÃ©taillÃ© :\n",
    "print(\"\\nğŸ“„ Classification report :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"baisse\",\"hausse\"]))\n",
    "\n",
    "# Matrice de confusion :\n",
    "print(\"ğŸ”¢ Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0e7a14-a5dc-408a-bf0a-1aae8114ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š RÂ² Score: -0.6016\n",
      "ğŸ“‰ Mean Squared Error: 0.3636\n",
      "ğŸ“Š Accuracy globale : 0.6363636363636364\n",
      "\n",
      "ğŸ”µ Classe BAISSE (0) :\n",
      "Precision : 0.7714285714285715\n",
      "Recall    : 0.627906976744186\n",
      "F1-score  : 0.6923076923076923\n",
      "\n",
      "ğŸŸ¢ Classe HAUSSE (1) :\n",
      "Precision : 0.4838709677419355\n",
      "Recall    : 0.6521739130434783\n",
      "F1-score  : 0.5555555555555556\n",
      "\n",
      "ğŸ“„ Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      baisse       0.77      0.63      0.69        43\n",
      "      hausse       0.48      0.65      0.56        23\n",
      "\n",
      "    accuracy                           0.64        66\n",
      "   macro avg       0.63      0.64      0.62        66\n",
      "weighted avg       0.67      0.64      0.64        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "#X = X.drop(columns=['NiveauSiteEUIWN'])\n",
    "y = target\n",
    "\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)  # Conversion des variables catÃ©gorielles en variables binaires\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# ğŸ”¹ Normalisation des variables explicatives uniquement\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Appliquer le scaler uniquement aux variables explicatives\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Appliquer la mÃªme transformation sur les donnÃ©es de test\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    penalty=\"elasticnet\",\n",
    "    l1_ratio=0.5,  # mÃ©lange L1/L2\n",
    "    solver=\"saga\"\n",
    ")\n",
    "# ğŸ”¹ CrÃ©ation du modÃ¨le ElasticNet avec alpha fixÃ© Ã  1\n",
    "elasticnet = logreg\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le\n",
    "elasticnet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ğŸ”¹ Faire des prÃ©dictions sur l'ensemble de test\n",
    "y_pred = elasticnet.predict(X_test_scaled)\n",
    "\n",
    "# ğŸ”¹ Ã‰valuer le modÃ¨le sur l'ensemble de test\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Affichage des rÃ©sultats\n",
    "print(f\"ğŸ“Š RÂ² Score: {r2:.4f}\")\n",
    "print(f\"ğŸ“‰ Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Faire des prÃ©dictions sur l'ensemble d'entraÃ®nement\n",
    "y_pred_train = elasticnet.predict(X_train_scaled)\n",
    "# Accuracy globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision par classe\n",
    "precision_baisse = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_hausse = precision_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Recall par classe\n",
    "recall_baisse = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_hausse = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# F1-score par classe\n",
    "f1_baisse = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_hausse = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"ğŸ“Š Accuracy globale :\", accuracy)\n",
    "print(\"\\nğŸ”µ Classe BAISSE (0) :\")\n",
    "print(\"Precision :\", precision_baisse)\n",
    "print(\"Recall    :\", recall_baisse)\n",
    "print(\"F1-score  :\", f1_baisse)\n",
    "\n",
    "print(\"\\nğŸŸ¢ Classe HAUSSE (1) :\")\n",
    "print(\"Precision :\", precision_hausse)\n",
    "print(\"Recall    :\", recall_hausse)\n",
    "print(\"F1-score  :\", f1_hausse)\n",
    "\n",
    "# Affichage dÃ©taillÃ© :\n",
    "print(\"\\nğŸ“„ Classification report :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"baisse\",\"hausse\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d61e3599-1b72-4657-842a-308e4a25252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__C': 0.1, 'model__l1_ratio': 0.1}\n",
      "ğŸ“Š Meilleur F1_macro (validation croisÃ©e) : 0.6427\n",
      "ğŸ“Š Ã‰valuation sur TEST\n",
      "ğŸ¯ Accuracy        : 0.6667\n",
      "ğŸ’  F1 Macro        : 0.6510\n",
      "ğŸ”· F1 Weighted     : 0.6734\n",
      "\n",
      "ğŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.78      0.67      0.72        43\n",
      "      HAUSSE       0.52      0.65      0.58        23\n",
      "\n",
      "    accuracy                           0.67        66\n",
      "   macro avg       0.65      0.66      0.65        66\n",
      "weighted avg       0.69      0.67      0.67        66\n",
      "\n",
      "\n",
      "ğŸ§© Matrice de confusion :\n",
      "[[29 14]\n",
      " [ 8 15]]\n",
      "\n",
      "ğŸ“Š Ã‰valuation sur TRAIN\n",
      "ğŸ¯ Accuracy (train) : 0.6780\n",
      "ğŸ’  F1 Macro (train) : 0.6767\n",
      "\n",
      "ğŸ“ˆ Coefficients du modÃ¨le :\n",
      "                Feature  Coefficient\n",
      "2        num__return_1d     0.031990\n",
      "3        num__return_3d     0.004541\n",
      "13  num__pos_channel_30     0.001362\n",
      "1           num__volume     0.000000\n",
      "6              num__MA7     0.000000\n",
      "7             num__MA30     0.000000\n",
      "8          num__MA_diff     0.000000\n",
      "0            num__price    -0.056499\n",
      "4        num__return_7d    -0.059626\n",
      "9           num__vol_7d    -0.102168\n",
      "12       num__lowest_30    -0.145475\n",
      "5       num__return_14d    -0.188186\n",
      "11      num__highest_30    -0.275644\n",
      "10         num__vol_MA7    -0.416357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,  random_state=42#, stratify = y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ğŸ”§ Pipeline de prÃ©traitement\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ğŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', LogisticRegression(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.01, 0.1, 1, 10],\n",
    "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ğŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ğŸ“Š Meilleur F1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ğŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# ğŸ“Š Ã‰valuation globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ğŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ğŸ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ğŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ğŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nğŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ğŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nğŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ğŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nğŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ğŸ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n",
    "\n",
    "# ğŸ“ˆ Extraire les coefficients du modÃ¨le\n",
    "coefs = best_model.named_steps['model'].coef_.flatten()\n",
    "features = best_model.named_steps['preprocessing'].get_feature_names_out()\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': coefs\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ“ˆ Coefficients du modÃ¨le :\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5644142-0656-46d8-91ae-32916f8d7c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__max_depth': 20, 'model__min_samples_split': 2, 'model__n_estimators': 50}\n",
      "ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.7712\n",
      "ğŸ“Š Ã‰valuation sur TEST\n",
      "ğŸ¯ Accuracy        : 0.8939\n",
      "ğŸ’  F1 Macro        : 0.8864\n",
      "ğŸ”· F1 Weighted     : 0.8953\n",
      "\n",
      "ğŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.95      0.88      0.92        43\n",
      "      HAUSSE       0.81      0.91      0.86        23\n",
      "\n",
      "    accuracy                           0.89        66\n",
      "   macro avg       0.88      0.90      0.89        66\n",
      "weighted avg       0.90      0.89      0.90        66\n",
      "\n",
      "\n",
      "ğŸ§© Matrice de confusion :\n",
      "[[38  5]\n",
      " [ 2 21]]\n",
      "\n",
      "ğŸ“Š Ã‰valuation sur TRAIN\n",
      "ğŸ¯ Accuracy (train) : 1.0000\n",
      "ğŸ’  F1 Macro (train) : 1.0000\n",
      "\n",
      "ğŸ“Š Ã‰valuation sur TEST\n",
      "ğŸ¯ Accuracy (test) : 0.8939\n",
      "ğŸ’  F1 Macro (test) : 0.8864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ğŸ”§ Pipeline de prÃ©traitement\n",
    "# Nous remplaÃ§ons le OneHotEncoder par un TargetEncoder pour les variables catÃ©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ğŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state=42))  # ModÃ¨le ElasticNet\n",
    "])\n",
    "\n",
    "# ParamÃ¨tres pour GridSearchCV\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 20, 30],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__n_estimators': [10, 50, 100, 200],  # Add more parameters for the model if needed\n",
    "    'model__min_samples_split': [3, 2, 4, 5, 6]\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ğŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ğŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ğŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ğŸ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ğŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ğŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nğŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ğŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nğŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ğŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nğŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ğŸ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n",
    "\n",
    "# ğŸ”µ PrÃ©dictions TEST\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# ğŸ“Š Ã‰valuation TEST\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "print(\"\\nğŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ğŸ¯ Accuracy (test) : {accuracy_test:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro (test) : {f1_macro_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "336ca620-a58e-49a4-b443-bfcaa199c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__max_depth': 10, 'model__min_samples_leaf': 5, 'model__min_samples_split': 3}\n",
      "ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.7114\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__max_depth': 10, 'model__min_samples_leaf': 5, 'model__min_samples_split': 3}\n",
      "ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.7114\n",
      "ğŸ“Š Ã‰valuation sur TEST\n",
      "ğŸ¯ Accuracy        : 0.8333\n",
      "ğŸ’  F1 Macro        : 0.8215\n",
      "ğŸ”· F1 Weighted     : 0.8354\n",
      "\n",
      "ğŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.90      0.84      0.87        43\n",
      "      HAUSSE       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.83        66\n",
      "   macro avg       0.82      0.83      0.82        66\n",
      "weighted avg       0.84      0.83      0.84        66\n",
      "\n",
      "\n",
      "ğŸ§© Matrice de confusion :\n",
      "[[36  7]\n",
      " [ 4 19]]\n",
      "\n",
      "ğŸ“Š Ã‰valuation sur TRAIN\n",
      "ğŸ¯ Accuracy (train) : 0.9015\n",
      "ğŸ’  F1 Macro (train) : 0.9015\n"
     ]
    }
   ],
   "source": [
    "#decisiontree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "# ğŸ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ğŸ”§ Pipeline de prÃ©traitement\n",
    "# Nous remplaÃ§ons le OneHotEncoder par un TargetEncoder pour les variables catÃ©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ğŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))  # ModÃ¨le ElasticNet\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 20, 30],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__min_samples_leaf': [2, 3, 4, 5, 6],  # Add more parameters for the model if needed\n",
    "    'model__min_samples_split': [3, 2, 4]\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ğŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ğŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ğŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ğŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ğŸ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ğŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ğŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nğŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ğŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nğŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ğŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nğŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ğŸ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd04a4aa-6581-407d-8216-8fdf358bc5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "âœ… Meilleur alpha trouvÃ© : {'model__learning_rate': 0.2, 'model__max_depth': 5, 'model__n_estimators': 300}\n",
      "ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : 0.7862\n",
      "ğŸ“Š Ã‰valuation sur TEST\n",
      "ğŸ¯ Accuracy        : 0.8636\n",
      "ğŸ’  F1 Macro        : 0.8581\n",
      "ğŸ”· F1 Weighted     : 0.8666\n",
      "\n",
      "ğŸ” Rapport dÃ©taillÃ© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.97      0.81      0.89        43\n",
      "      HAUSSE       0.73      0.96      0.83        23\n",
      "\n",
      "    accuracy                           0.86        66\n",
      "   macro avg       0.85      0.89      0.86        66\n",
      "weighted avg       0.89      0.86      0.87        66\n",
      "\n",
      "\n",
      "ğŸ§© Matrice de confusion :\n",
      "[[35  8]\n",
      " [ 1 22]]\n",
      "\n",
      "ğŸ“Š Ã‰valuation sur TRAIN\n",
      "ğŸ¯ Accuracy (train) : 1.0000\n",
      "ğŸ’  F1 Macro (train) : 1.0000\n"
     ]
    }
   ],
   "source": [
    "#gradientboosting\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ² SÃ©paration des donnÃ©es avec stratification basÃ©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# ğŸ”§ Pipeline de prÃ©traitement\n",
    "# Nous remplaÃ§ons le OneHotEncoder par un TargetEncoder pour les variables catÃ©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ğŸ’¡ Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', GradientBoostingClassifier(random_state=42))  # ModÃ¨le ElasticNet\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 2, 3],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__n_estimators': [100, 200, 300, 50],  # Add more parameters for the model if needed\n",
    "    'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ğŸš€ EntraÃ®nement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Meilleur modÃ¨le trouvÃ©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"âœ… Meilleur alpha trouvÃ© : {grid_search.best_params_}\")\n",
    "print(f\"ğŸ“Š Meilleur f1_macro (validation croisÃ©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# ğŸŸ¢ PrÃ©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"ğŸ“Š Ã‰valuation sur TEST\")\n",
    "print(f\"ğŸ¯ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"ğŸ”· F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# ğŸ“Š Rapport dÃ©taillÃ© par classe\n",
    "print(\"\\nğŸ” Rapport dÃ©taillÃ© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# ğŸ§© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nğŸ§© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# ğŸ”µ Ã‰valuation entraÃ®nement (pour voir lâ€™overfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nğŸ“Š Ã‰valuation sur TRAIN\")\n",
    "print(f\"ğŸ¯ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"ğŸ’  F1 Macro (train) : {f1_macro_train:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda Base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
