{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea4e09b-7cd2-40de-9f3e-77766c328ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13df5bef-eb3d-4cb5-a0ac-5deb06ebce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a154a6bf-bc56-44c5-b5f0-00c425f1c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target_up\"] = (df[\"price\"].shift(-14) > df[\"price\"]).astype(int)\n",
    "df = df.iloc[:-14]   # retirer la derni√®re ligne sans cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3134340-471c-416d-9bb1-9fcdbac896dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choix de la cible  \n",
    "\n",
    "target = df['target_up']\n",
    "target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522468fd-5b5d-44ac-b264-0928bd508d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataexplicative = df.drop(columns=['date', 'target_up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad00375-b0b6-406e-8792-f968b4e8fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b4c7d6-8fe7-4fc4-9105-ac59b654db94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataexplicative.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8665eb-162d-4b9d-b5ca-fb622ab3773d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_7d</th>\n",
       "      <th>return_14d</th>\n",
       "      <th>MA7</th>\n",
       "      <th>MA30</th>\n",
       "      <th>MA_diff</th>\n",
       "      <th>vol_7d</th>\n",
       "      <th>vol_MA7</th>\n",
       "      <th>highest_30</th>\n",
       "      <th>lowest_30</th>\n",
       "      <th>pos_channel_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>85762.206093</td>\n",
       "      <td>8.639245e+10</td>\n",
       "      <td>-2.079255</td>\n",
       "      <td>-6.401507</td>\n",
       "      <td>-2.251372</td>\n",
       "      <td>-8.316363</td>\n",
       "      <td>88905.340674</td>\n",
       "      <td>92658.963301</td>\n",
       "      <td>-3753.622627</td>\n",
       "      <td>2.130685</td>\n",
       "      <td>6.254074e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>85762.206093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>81256.301578</td>\n",
       "      <td>9.737908e+10</td>\n",
       "      <td>-5.253951</td>\n",
       "      <td>-8.561380</td>\n",
       "      <td>-9.078764</td>\n",
       "      <td>-13.985412</td>\n",
       "      <td>87746.242070</td>\n",
       "      <td>92198.806835</td>\n",
       "      <td>-4452.564766</td>\n",
       "      <td>2.575709</td>\n",
       "      <td>6.489116e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>81256.301578</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>82171.816288</td>\n",
       "      <td>3.360760e+10</td>\n",
       "      <td>1.126700</td>\n",
       "      <td>-6.178655</td>\n",
       "      <td>-7.060250</td>\n",
       "      <td>-13.405739</td>\n",
       "      <td>86854.491413</td>\n",
       "      <td>91858.415534</td>\n",
       "      <td>-5003.924121</td>\n",
       "      <td>2.740059</td>\n",
       "      <td>6.338302e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>81256.301578</td>\n",
       "      <td>0.053331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>81307.886643</td>\n",
       "      <td>6.256266e+10</td>\n",
       "      <td>-1.051370</td>\n",
       "      <td>-5.193802</td>\n",
       "      <td>-10.370709</td>\n",
       "      <td>-15.292969</td>\n",
       "      <td>85510.510417</td>\n",
       "      <td>91525.824561</td>\n",
       "      <td>-6015.314145</td>\n",
       "      <td>2.239811</td>\n",
       "      <td>6.490053e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>81256.301578</td>\n",
       "      <td>0.003005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>79409.746949</td>\n",
       "      <td>8.265206e+10</td>\n",
       "      <td>-2.334509</td>\n",
       "      <td>-2.272506</td>\n",
       "      <td>-13.334405</td>\n",
       "      <td>-14.128123</td>\n",
       "      <td>83765.079436</td>\n",
       "      <td>91108.675922</td>\n",
       "      <td>-7343.596486</td>\n",
       "      <td>1.946201</td>\n",
       "      <td>6.835965e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>79409.746949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price        volume  return_1d  return_3d  return_7d  return_14d  \\\n",
       "329  85762.206093  8.639245e+10  -2.079255  -6.401507  -2.251372   -8.316363   \n",
       "330  81256.301578  9.737908e+10  -5.253951  -8.561380  -9.078764  -13.985412   \n",
       "331  82171.816288  3.360760e+10   1.126700  -6.178655  -7.060250  -13.405739   \n",
       "332  81307.886643  6.256266e+10  -1.051370  -5.193802 -10.370709  -15.292969   \n",
       "333  79409.746949  8.265206e+10  -2.334509  -2.272506 -13.334405  -14.128123   \n",
       "\n",
       "              MA7          MA30      MA_diff    vol_7d       vol_MA7  \\\n",
       "329  88905.340674  92658.963301 -3753.622627  2.130685  6.254074e+10   \n",
       "330  87746.242070  92198.806835 -4452.564766  2.575709  6.489116e+10   \n",
       "331  86854.491413  91858.415534 -5003.924121  2.740059  6.338302e+10   \n",
       "332  85510.510417  91525.824561 -6015.314145  2.239811  6.490053e+10   \n",
       "333  83765.079436  91108.675922 -7343.596486  1.946201  6.835965e+10   \n",
       "\n",
       "       highest_30     lowest_30  pos_channel_30  \n",
       "329  98422.812122  85762.206093        0.000000  \n",
       "330  98422.812122  81256.301578        0.000000  \n",
       "331  98422.812122  81256.301578        0.053331  \n",
       "332  98422.812122  81256.301578        0.003005  \n",
       "333  98422.812122  79409.746949        0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataexplicative.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11684d27-4a09-44ae-9592-11d567d1744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_7d</th>\n",
       "      <th>return_14d</th>\n",
       "      <th>MA7</th>\n",
       "      <th>MA30</th>\n",
       "      <th>MA_diff</th>\n",
       "      <th>vol_7d</th>\n",
       "      <th>vol_MA7</th>\n",
       "      <th>highest_30</th>\n",
       "      <th>lowest_30</th>\n",
       "      <th>pos_channel_30</th>\n",
       "      <th>target_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>85762.206093</td>\n",
       "      <td>8.639245e+10</td>\n",
       "      <td>-2.079255</td>\n",
       "      <td>-6.401507</td>\n",
       "      <td>-2.251372</td>\n",
       "      <td>-8.316363</td>\n",
       "      <td>88905.340674</td>\n",
       "      <td>92658.963301</td>\n",
       "      <td>-3753.622627</td>\n",
       "      <td>2.130685</td>\n",
       "      <td>6.254074e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>85762.206093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2025-11-15</td>\n",
       "      <td>81256.301578</td>\n",
       "      <td>9.737908e+10</td>\n",
       "      <td>-5.253951</td>\n",
       "      <td>-8.561380</td>\n",
       "      <td>-9.078764</td>\n",
       "      <td>-13.985412</td>\n",
       "      <td>87746.242070</td>\n",
       "      <td>92198.806835</td>\n",
       "      <td>-4452.564766</td>\n",
       "      <td>2.575709</td>\n",
       "      <td>6.489116e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>81256.301578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2025-11-16</td>\n",
       "      <td>82171.816288</td>\n",
       "      <td>3.360760e+10</td>\n",
       "      <td>1.126700</td>\n",
       "      <td>-6.178655</td>\n",
       "      <td>-7.060250</td>\n",
       "      <td>-13.405739</td>\n",
       "      <td>86854.491413</td>\n",
       "      <td>91858.415534</td>\n",
       "      <td>-5003.924121</td>\n",
       "      <td>2.740059</td>\n",
       "      <td>6.338302e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>81256.301578</td>\n",
       "      <td>0.053331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>81307.886643</td>\n",
       "      <td>6.256266e+10</td>\n",
       "      <td>-1.051370</td>\n",
       "      <td>-5.193802</td>\n",
       "      <td>-10.370709</td>\n",
       "      <td>-15.292969</td>\n",
       "      <td>85510.510417</td>\n",
       "      <td>91525.824561</td>\n",
       "      <td>-6015.314145</td>\n",
       "      <td>2.239811</td>\n",
       "      <td>6.490053e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>81256.301578</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>79409.746949</td>\n",
       "      <td>8.265206e+10</td>\n",
       "      <td>-2.334509</td>\n",
       "      <td>-2.272506</td>\n",
       "      <td>-13.334405</td>\n",
       "      <td>-14.128123</td>\n",
       "      <td>83765.079436</td>\n",
       "      <td>91108.675922</td>\n",
       "      <td>-7343.596486</td>\n",
       "      <td>1.946201</td>\n",
       "      <td>6.835965e+10</td>\n",
       "      <td>98422.812122</td>\n",
       "      <td>79409.746949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date         price        volume  return_1d  return_3d  return_7d  \\\n",
       "329  2025-11-14  85762.206093  8.639245e+10  -2.079255  -6.401507  -2.251372   \n",
       "330  2025-11-15  81256.301578  9.737908e+10  -5.253951  -8.561380  -9.078764   \n",
       "331  2025-11-16  82171.816288  3.360760e+10   1.126700  -6.178655  -7.060250   \n",
       "332  2025-11-17  81307.886643  6.256266e+10  -1.051370  -5.193802 -10.370709   \n",
       "333  2025-11-18  79409.746949  8.265206e+10  -2.334509  -2.272506 -13.334405   \n",
       "\n",
       "     return_14d           MA7          MA30      MA_diff    vol_7d  \\\n",
       "329   -8.316363  88905.340674  92658.963301 -3753.622627  2.130685   \n",
       "330  -13.985412  87746.242070  92198.806835 -4452.564766  2.575709   \n",
       "331  -13.405739  86854.491413  91858.415534 -5003.924121  2.740059   \n",
       "332  -15.292969  85510.510417  91525.824561 -6015.314145  2.239811   \n",
       "333  -14.128123  83765.079436  91108.675922 -7343.596486  1.946201   \n",
       "\n",
       "          vol_MA7    highest_30     lowest_30  pos_channel_30  target_up  \n",
       "329  6.254074e+10  98422.812122  85762.206093        0.000000          0  \n",
       "330  6.489116e+10  98422.812122  81256.301578        0.000000          0  \n",
       "331  6.338302e+10  98422.812122  81256.301578        0.053331          0  \n",
       "332  6.490053e+10  98422.812122  81256.301578        0.003005          0  \n",
       "333  6.835965e+10  98422.812122  79409.746949        0.000000          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac93971-81e2-4021-8af7-67bd1a7c8cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329    0\n",
       "330    0\n",
       "331    0\n",
       "332    0\n",
       "333    1\n",
       "Name: target_up, dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf05b67-ade6-4c16-b36e-647e2e7ac248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Nombre de valeurs identiques dans Train/Test : 0\n",
      "üìä Accuracy globale : 0.47761194029850745\n",
      "\n",
      "üîµ Classe BAISSE (0) :\n",
      "Precision : 0.5142857142857142\n",
      "Recall    : 0.5\n",
      "F1-score  : 0.5070422535211268\n",
      "\n",
      "üü¢ Classe HAUSSE (1) :\n",
      "Precision : 0.4375\n",
      "Recall    : 0.45161290322580644\n",
      "F1-score  : 0.4444444444444444\n",
      "\n",
      "üìÑ Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      baisse       0.51      0.50      0.51        36\n",
      "      hausse       0.44      0.45      0.44        31\n",
      "\n",
      "    accuracy                           0.48        67\n",
      "   macro avg       0.48      0.48      0.48        67\n",
      "weighted avg       0.48      0.48      0.48        67\n",
      "\n",
      "üî¢ Matrice de confusion :\n",
      "[[18 18]\n",
      " [17 14]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "#X = X.drop(columns=['NiveauSiteEUIWN'])\n",
    "y = target\n",
    "\n",
    "# Encodage One-Hot bas√© sur X\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Normalisation des donn√©es \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # OK : on apprend la normalisation sur l'entra√Ænement\n",
    "X_test_scaled = scaler.transform(X_test)        # OK : on applique la m√™me normalisation au test\n",
    "\n",
    "# Appliquer le mod√®le DummyRegressor\n",
    "dummy_regressor = DummyClassifier(strategy=\"stratified\")  # 'mean' pour pr√©dire la moyenne des cibles\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Faire des pr√©dictions\n",
    "y_pred = dummy_regressor.predict(X_test)\n",
    "\n",
    "# Calculer les erreurs\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# V√©rifier si des valeurs de test sont d√©j√† vues en entra√Ænement\n",
    "intersection = set(X_train.index).intersection(set(X_test.index))\n",
    "print(f\"üîç Nombre de valeurs identiques dans Train/Test : {len(intersection)}\")\n",
    "\n",
    "# Accuracy globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision par classe\n",
    "precision_baisse = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_hausse = precision_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Recall par classe\n",
    "recall_baisse = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_hausse = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# F1-score par classe\n",
    "f1_baisse = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_hausse = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"üìä Accuracy globale :\", accuracy)\n",
    "print(\"\\nüîµ Classe BAISSE (0) :\")\n",
    "print(\"Precision :\", precision_baisse)\n",
    "print(\"Recall    :\", recall_baisse)\n",
    "print(\"F1-score  :\", f1_baisse)\n",
    "\n",
    "print(\"\\nüü¢ Classe HAUSSE (1) :\")\n",
    "print(\"Precision :\", precision_hausse)\n",
    "print(\"Recall    :\", recall_hausse)\n",
    "print(\"F1-score  :\", f1_hausse)\n",
    "\n",
    "# Affichage d√©taill√© :\n",
    "print(\"\\nüìÑ Classification report :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"baisse\",\"hausse\"]))\n",
    "\n",
    "# Matrice de confusion :\n",
    "print(\"üî¢ Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f0e7a14-a5dc-408a-bf0a-1aae8114ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä R¬≤ Score: -1.0412\n",
      "üìâ Mean Squared Error: 0.5075\n",
      "üìä Accuracy globale : 0.4925373134328358\n",
      "\n",
      "üîµ Classe BAISSE (0) :\n",
      "Precision : 0.55\n",
      "Recall    : 0.3055555555555556\n",
      "F1-score  : 0.39285714285714285\n",
      "\n",
      "üü¢ Classe HAUSSE (1) :\n",
      "Precision : 0.46808510638297873\n",
      "Recall    : 0.7096774193548387\n",
      "F1-score  : 0.5641025641025641\n",
      "\n",
      "üìÑ Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      baisse       0.55      0.31      0.39        36\n",
      "      hausse       0.47      0.71      0.56        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.51      0.51      0.48        67\n",
      "weighted avg       0.51      0.49      0.47        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "#X = X.drop(columns=['NiveauSiteEUIWN'])\n",
    "y = target\n",
    "\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)  # Conversion des variables cat√©gorielles en variables binaires\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# üîπ Normalisation des variables explicatives uniquement\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Appliquer le scaler uniquement aux variables explicatives\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Appliquer la m√™me transformation sur les donn√©es de test\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    penalty=\"elasticnet\",\n",
    "    l1_ratio=0.5,  # m√©lange L1/L2\n",
    "    solver=\"saga\"\n",
    ")\n",
    "# üîπ Cr√©ation du mod√®le ElasticNet avec alpha fix√© √† 1\n",
    "elasticnet = logreg\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "elasticnet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# üîπ Faire des pr√©dictions sur l'ensemble de test\n",
    "y_pred = elasticnet.predict(X_test_scaled)\n",
    "\n",
    "# üîπ √âvaluer le mod√®le sur l'ensemble de test\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(f\"üìä R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"üìâ Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Faire des pr√©dictions sur l'ensemble d'entra√Ænement\n",
    "y_pred_train = elasticnet.predict(X_train_scaled)\n",
    "# Accuracy globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision par classe\n",
    "precision_baisse = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_hausse = precision_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Recall par classe\n",
    "recall_baisse = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_hausse = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# F1-score par classe\n",
    "f1_baisse = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_hausse = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"üìä Accuracy globale :\", accuracy)\n",
    "print(\"\\nüîµ Classe BAISSE (0) :\")\n",
    "print(\"Precision :\", precision_baisse)\n",
    "print(\"Recall    :\", recall_baisse)\n",
    "print(\"F1-score  :\", f1_baisse)\n",
    "\n",
    "print(\"\\nüü¢ Classe HAUSSE (1) :\")\n",
    "print(\"Precision :\", precision_hausse)\n",
    "print(\"Recall    :\", recall_hausse)\n",
    "print(\"F1-score  :\", f1_hausse)\n",
    "\n",
    "# Affichage d√©taill√© :\n",
    "print(\"\\nüìÑ Classification report :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"baisse\",\"hausse\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d61e3599-1b72-4657-842a-308e4a25252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "‚úÖ Meilleur alpha trouv√© : {'model__C': 1, 'model__l1_ratio': 0.3}\n",
      "üìä Meilleur F1_macro (validation crois√©e) : 0.4746\n",
      "üìä √âvaluation sur TEST\n",
      "üéØ Accuracy        : 0.4925\n",
      "üí† F1 Macro        : 0.4785\n",
      "üî∑ F1 Weighted     : 0.4721\n",
      "\n",
      "üîç Rapport d√©taill√© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.55      0.31      0.39        36\n",
      "      HAUSSE       0.47      0.71      0.56        31\n",
      "\n",
      "    accuracy                           0.49        67\n",
      "   macro avg       0.51      0.51      0.48        67\n",
      "weighted avg       0.51      0.49      0.47        67\n",
      "\n",
      "\n",
      "üß© Matrice de confusion :\n",
      "[[11 25]\n",
      " [ 9 22]]\n",
      "\n",
      "üìä √âvaluation sur TRAIN\n",
      "üéØ Accuracy (train) : 0.5993\n",
      "üí† F1 Macro (train) : 0.5597\n",
      "\n",
      "üìà Coefficients du mod√®le :\n",
      "                Feature  Coefficient\n",
      "13  num__pos_channel_30     0.129052\n",
      "1           num__volume     0.058282\n",
      "4        num__return_7d     0.049754\n",
      "11      num__highest_30     0.015839\n",
      "0            num__price     0.000000\n",
      "6              num__MA7     0.000000\n",
      "7             num__MA30     0.000000\n",
      "9           num__vol_7d    -0.018962\n",
      "8          num__MA_diff    -0.051494\n",
      "2        num__return_1d    -0.090388\n",
      "3        num__return_3d    -0.107137\n",
      "5       num__return_14d    -0.223646\n",
      "12       num__lowest_30    -0.232563\n",
      "10         num__vol_MA7    -0.246454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# üé≤ S√©paration des donn√©es avec stratification bas√©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,  random_state=42#, stratify = y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# üîß Pipeline de pr√©traitement\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# üí° Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', LogisticRegression(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.01, 0.1, 1, 10],\n",
    "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# üöÄ Entra√Ænement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Meilleur mod√®le trouv√©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"‚úÖ Meilleur alpha trouv√© : {grid_search.best_params_}\")\n",
    "print(f\"üìä Meilleur F1_macro (validation crois√©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# üü¢ Pr√©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# üìä √âvaluation globale\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"üìä √âvaluation sur TEST\")\n",
    "print(f\"üéØ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"üí† F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"üî∑ F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# üìä Rapport d√©taill√© par classe\n",
    "print(\"\\nüîç Rapport d√©taill√© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# üß© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüß© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# üîµ √âvaluation entra√Ænement (pour voir l‚Äôoverfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nüìä √âvaluation sur TRAIN\")\n",
    "print(f\"üéØ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"üí† F1 Macro (train) : {f1_macro_train:.4f}\")\n",
    "\n",
    "# üìà Extraire les coefficients du mod√®le\n",
    "coefs = best_model.named_steps['model'].coef_.flatten()\n",
    "features = best_model.named_steps['preprocessing'].get_feature_names_out()\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': coefs\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nüìà Coefficients du mod√®le :\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5644142-0656-46d8-91ae-32916f8d7c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "‚úÖ Meilleur alpha trouv√© : {'model__max_depth': 10, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "üìä Meilleur f1_macro (validation crois√©e) : 0.6414\n",
      "üìä √âvaluation sur TEST\n",
      "üéØ Accuracy        : 0.5522\n",
      "üí† F1 Macro        : 0.5398\n",
      "üî∑ F1 Weighted     : 0.5342\n",
      "\n",
      "üîç Rapport d√©taill√© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.65      0.36      0.46        36\n",
      "      HAUSSE       0.51      0.77      0.62        31\n",
      "\n",
      "    accuracy                           0.55        67\n",
      "   macro avg       0.58      0.57      0.54        67\n",
      "weighted avg       0.59      0.55      0.53        67\n",
      "\n",
      "\n",
      "üß© Matrice de confusion :\n",
      "[[13 23]\n",
      " [ 7 24]]\n",
      "\n",
      "üìä √âvaluation sur TRAIN\n",
      "üéØ Accuracy (train) : 1.0000\n",
      "üí† F1 Macro (train) : 1.0000\n",
      "\n",
      "üìä √âvaluation sur TEST\n",
      "üéØ Accuracy (test) : 0.5522\n",
      "üí† F1 Macro (test) : 0.5398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# üé≤ S√©paration des donn√©es avec stratification bas√©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# üîß Pipeline de pr√©traitement\n",
    "# Nous rempla√ßons le OneHotEncoder par un TargetEncoder pour les variables cat√©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# üí° Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state=42))  # Mod√®le ElasticNet\n",
    "])\n",
    "\n",
    "# Param√®tres pour GridSearchCV\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 20, 30],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__n_estimators': [10, 50, 100, 200],  # Add more parameters for the model if needed\n",
    "    'model__min_samples_split': [3, 2, 4, 5, 6]\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# üöÄ Entra√Ænement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Meilleur mod√®le trouv√©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"‚úÖ Meilleur alpha trouv√© : {grid_search.best_params_}\")\n",
    "print(f\"üìä Meilleur f1_macro (validation crois√©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# üü¢ Pr√©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"üìä √âvaluation sur TEST\")\n",
    "print(f\"üéØ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"üí† F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"üî∑ F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# üìä Rapport d√©taill√© par classe\n",
    "print(\"\\nüîç Rapport d√©taill√© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# üß© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüß© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# üîµ √âvaluation entra√Ænement (pour voir l‚Äôoverfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nüìä √âvaluation sur TRAIN\")\n",
    "print(f\"üéØ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"üí† F1 Macro (train) : {f1_macro_train:.4f}\")\n",
    "\n",
    "# üîµ Pr√©dictions TEST\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# üìä √âvaluation TEST\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_macro_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "print(\"\\nüìä √âvaluation sur TEST\")\n",
    "print(f\"üéØ Accuracy (test) : {accuracy_test:.4f}\")\n",
    "print(f\"üí† F1 Macro (test) : {f1_macro_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "336ca620-a58e-49a4-b443-bfcaa199c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "‚úÖ Meilleur alpha trouv√© : {'model__max_depth': 20, 'model__min_samples_leaf': 2, 'model__min_samples_split': 3}\n",
      "üìä Meilleur f1_macro (validation crois√©e) : 0.5715\n",
      "‚úÖ Meilleur alpha trouv√© : {'model__max_depth': 20, 'model__min_samples_leaf': 2, 'model__min_samples_split': 3}\n",
      "üìä Meilleur f1_macro (validation crois√©e) : 0.5715\n",
      "üìä √âvaluation sur TEST\n",
      "üéØ Accuracy        : 0.6119\n",
      "üí† F1 Macro        : 0.6077\n",
      "üî∑ F1 Weighted     : 0.6046\n",
      "\n",
      "üîç Rapport d√©taill√© par classe :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BAISSE       0.71      0.47      0.57        36\n",
      "      HAUSSE       0.56      0.77      0.65        31\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.63      0.62      0.61        67\n",
      "weighted avg       0.64      0.61      0.60        67\n",
      "\n",
      "\n",
      "üß© Matrice de confusion :\n",
      "[[17 19]\n",
      " [ 7 24]]\n",
      "\n",
      "üìä √âvaluation sur TRAIN\n",
      "üéØ Accuracy (train) : 0.9588\n",
      "üí† F1 Macro (train) : 0.9586\n"
     ]
    }
   ],
   "source": [
    "#decisiontree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "# üé≤ S√©paration des donn√©es avec stratification bas√©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# üîß Pipeline de pr√©traitement\n",
    "# Nous rempla√ßons le OneHotEncoder par un TargetEncoder pour les variables cat√©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# üí° Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', DecisionTreeClassifier(random_state=42))  # Mod√®le ElasticNet\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 20, 30],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__min_samples_leaf': [2, 3, 4, 5, 6],  # Add more parameters for the model if needed\n",
    "    'model__min_samples_split': [3, 2, 4]\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# üöÄ Entra√Ænement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Meilleur mod√®le trouv√©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"‚úÖ Meilleur alpha trouv√© : {grid_search.best_params_}\")\n",
    "print(f\"üìä Meilleur f1_macro (validation crois√©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# üü¢ Pr√©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"‚úÖ Meilleur alpha trouv√© : {grid_search.best_params_}\")\n",
    "print(f\"üìä Meilleur f1_macro (validation crois√©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# üü¢ Pr√©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"üìä √âvaluation sur TEST\")\n",
    "print(f\"üéØ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"üí† F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"üî∑ F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# üìä Rapport d√©taill√© par classe\n",
    "print(\"\\nüîç Rapport d√©taill√© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# üß© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüß© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# üîµ √âvaluation entra√Ænement (pour voir l‚Äôoverfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nüìä √âvaluation sur TRAIN\")\n",
    "print(f\"üéØ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"üí† F1 Macro (train) : {f1_macro_train:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd04a4aa-6581-407d-8216-8fdf358bc5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 56\u001b[0m\n\u001b[0;32m     46\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     47\u001b[0m     pipeline,\n\u001b[0;32m     48\u001b[0m     param_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# üöÄ Entra√Ænement avec GridSearchCV\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# ‚úÖ Meilleur mod√®le trouv√©\u001b[39;00m\n\u001b[0;32m     59\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#gradientboosting\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder  # Nous utilisons category_encoders pour le Target Encoding\n",
    "\n",
    "# Variables explicatives et cible\n",
    "X = dataexplicative\n",
    "y = target\n",
    "\n",
    "\n",
    "\n",
    "# üé≤ S√©paration des donn√©es avec stratification bas√©e sur les quartiles de la cible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42#, stratify=y_quartiles  # Stratification sur y_quartiles\n",
    ")\n",
    "\n",
    "# üîß Pipeline de pr√©traitement\n",
    "# Nous rempla√ßons le OneHotEncoder par un TargetEncoder pour les variables cat√©gorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X_train.select_dtypes(exclude='object').columns.tolist()),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X_train.select_dtypes(include='object').columns.tolist())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# üí° Pipeline complet avec GridSearchCV\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', GradientBoostingClassifier(random_state=42))  # Mod√®le ElasticNet\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__max_depth': [10, 5, 2, 3],  # Using model__ to specify RandomForestRegressor\n",
    "    'model__n_estimators': [100, 200, 300, 50],  # Add more parameters for the model if needed\n",
    "    'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    # Add other hyperparameters for preprocessing steps if needed\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# üöÄ Entra√Ænement avec GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Meilleur mod√®le trouv√©\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"‚úÖ Meilleur alpha trouv√© : {grid_search.best_params_}\")\n",
    "print(f\"üìä Meilleur f1_macro (validation crois√©e) : {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# üü¢ Pr√©dictions sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"üìä √âvaluation sur TEST\")\n",
    "print(f\"üéØ Accuracy        : {accuracy:.4f}\")\n",
    "print(f\"üí† F1 Macro        : {f1_macro:.4f}\")\n",
    "print(f\"üî∑ F1 Weighted     : {f1_weighted:.4f}\")\n",
    "\n",
    "# üìä Rapport d√©taill√© par classe\n",
    "print(\"\\nüîç Rapport d√©taill√© par classe :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BAISSE', 'HAUSSE']))\n",
    "\n",
    "# üß© Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüß© Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# üîµ √âvaluation entra√Ænement (pour voir l‚Äôoverfitting)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_macro_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "\n",
    "print(\"\\nüìä √âvaluation sur TRAIN\")\n",
    "print(f\"üéØ Accuracy (train) : {accuracy_train:.4f}\")\n",
    "print(f\"üí† F1 Macro (train) : {f1_macro_train:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda Base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
